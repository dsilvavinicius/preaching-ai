<!DOCTYPE html>
<meta charset="utf-8">

<html>

<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
    <title>Preaching-AI</title>
    <meta property="og:description" content="Preaching-AI"/>
    <meta property="og:image" itemprop="image" content="https://dsilvavinicius.github.io/nise/assets/representative.jpg">
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">
    <link rel='stylesheet' type='text/css' href='styles.css'/>

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:creator" content="@dsilvavinicius">
    <meta name="twitter:title" content="Preaching-AI">
    <meta name="twitter:description" content="Preaching-AI is a research project aiming to understand the intersection of technology and religion, particularly how humans interact with artificial inteligence (AI) in this context.">
    <meta name="twitter:image" content="https://dsilvavinicius.github.io/nise/assets/representative.jpg">

    <meta name="viewport" content="width=device-width, initial-scale=1">
</head>

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>

<body>
<div class="container">
    <div class="paper-title">
        <img src="assets/logo.png" alt="logo" class="logo">
    </div>

    <div class="language-selector">
        <a href="index.html">English (US)</a> |
        <a href="zh.html">‰∏≠Êñá</a> |
        <a href="hi.html">‡§π‡§ø‡§®‡•ç‡§¶‡•Ä</a> |
        <a href="fr.html">Fran√ßais</a> |
        <a href="es.html">Espa√±ol</a> |
        <a href="pt-br.html">Portugu√™s (BR)</a>
    </div>

    <div id="authors">
        <div class="author-row">
            <div class="col-3 text-center"><a href="https://dsilvavinicius.github.io">Vin√≠cius da Silva</a><sup>1</sup></div>
            <div class="col-3 text-center"><a href="https://lvelho.impa.br/">Luiz Velho</a><sup>2</sup></div>
            <div class="col-3 text-center"><a href="https://www.inf.puc-rio.br/blog/professor/alberto-barbosa-raposo/">Alberto Raposo</a><sup>1</sup></div>
        </div>

        <div class="affil-row">
            <div class="col-2 text-center"><sup>1</sup>PUC-Rio</div>
            <div class="col-2 text-center"><sup>2</sup>IMPA</div>
        </div>

        <div style="clear: both">
            <div class="paper-btn-parent">
                <a class="paper-btn" href="https://forms.gle/DBkFAYzbQ9UfWMyX9">
                    <span class="material-icons"> description </span>
                    3-min Form
                </a>
                <a class="paper-btn" href="https://www.youtube.com/channel/UCWRkxIPqsL6AJ7rKjx79SyA">
                    <span class="material-icons"> videocam </span>
                    Youtube
                </a>
                <!--<a class="paper-btn" href="https://github.com/dsilvavinicius/nise">
                    <span class="material-icons"> code </span>
                    Code
                </a>-->
            </div>
        </div>
    </div>
    </div>

    <section id="teaser-videos">
        <!--
        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Coarse
            </p>
        </figure>

        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Neural Implicit Normal Mapping
            </p>
        </figure>

        <figure style="width: 33%; float: left">
            <p class="caption_bold">
                Baseline
            </p>
        </figure>
        -->

        <figure style="width: 100%; float: left">
            <video class="centered" width="100%" autoplay muted loop playsinline>
                <source src="assets/Preaching-AI - Teaser.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </figure>

        <figure style="width: 100%; float: left">
            <p class="caption_justify">
                AI-generated preaching videos. The Artificial Intelligence (AI) is responsible for generating the sermon (given some theological and time constraints), translating the text to a specific language, generating the audio speaking the sermon in that language, and the video of a selected avatar speaking it.
            </p>
        </figure>
    </section>

    <section id="news">
        <h2>News</h2>
        <hr>
        <div class="row">
            <!-- <div><span class="material-icons"> description </span> [Jul 14th 2023] Paper accepted to #ICCV23.
            <blockquote class="twitter-tweet" data-theme="dark"><p lang="en" dir="ltr">üì¢New ICCV Paper: Neural Surface Evolution!üì¢<br>Do you want to evolve your implicit surface using the Level Set equation without any supervision at the boundary conditions or using discretized methods such as FEM? Follow the üßµ (rendering powered by <a href="https://twitter.com/nvidiaomniverse?ref_src=twsrc%5Etfw">@nvidiaomniverse</a>). <a href="https://t.co/sofIf7pqpI">pic.twitter.com/sofIf7pqpI</a></p>&mdash; Vin√≠cius da Silva (@dsilvavinicius) <a href="https://twitter.com/dsilvavinicius/status/1679991981718609925?ref_src=twsrc%5Etfw">July 14, 2023</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></div>
            <div><span class="material-icons"> description </span> [Jul 20th 2023] Page online.</div> -->
            <div><span class="material-icons"> description </span> [Oct 5th 2023] Page online.
        </div>
    </section>

    <section id="Motivation" style="text-align: justify;"/>
        <h2>Motivation</h2>
        <hr>
        <p>
            Preaching-AI is a research project aiming to understand the intersection of technology and religion, particularly how humans interact with artificial inteligence (AI) avatars in this context. With the popularization of AI generative approaches, several helpful applications have been emerging. One of them is the generation of videos of AI avatars. A particular case is making an avatar speak about a specific theme under a set of constraints. Preaching is an interesting application in this scenario for a number of reasons:
            
            <ul>
                <li>Current generative videos of avatars are limited. The tools have difficulties representing excited and emotive speeches. Preaching is a good-case scenario because it tends to be calm, not varying too much in tone and speed, nor having abrupt movements.</li>
                <li>Current Large Language Model (LLM) chatbots are considerably well versed in theology, given the abundant literature they are trained upon.</li>
                <li>Language is an important barrier for preachers. LLM chatbots are also good at translating text.</li>
                <li>Appearance may also be a barrier. An avatar may have a custom appearance, which may help connecting with the community at hand.</li>
                <li>Avatars cannot suffer the effects of religious intolerance.</li>
                <li>Religion is a theme present in the lives of billions of people.</li>
            </ul>
        </p>
    </section>

    <section id="Motivation" style="text-align: justify;"/>
        <h2>Participate!</h2>
        <p>
            Given the speed of the advances in AI technology, Preaching-AI is a participative project from the ground up. Help us understand your experience with AI-generated sermons. Your insights will contribute to this research project and will help the development of future tools to improve religion practice through technology. Please fill the following 3-min form.
        </p>
        <iframe src="https://docs.google.com/forms/d/e/1FAIpQLSdKQbRvoeYZlx_Znhz4gz9e3BhIc6uh0e1NttCXbsrToUoEcg/viewform?embedded=true" width="100%" height="600" frameborder="0" marginheight="0" marginwidth="0">Loading‚Ä¶</iframe>
    </section>

    <section id="results">
        <h2>Case Study: Christian Preaching</h2>
        <hr>

        <p>We choose Christianity preaching as a pilot case study based on religion demographics. In this case we provided the following prompt for the text-generating AI:</p>
        
        <p>"Create the script for a 45 seconds to 1 minute video with a Christian evangelistic preaching to the general public. It should be theologically flawless, centered into how Christ is the way to a better life near God. It should also be tranquilizing, soothing, a good message for the heart. It should end with a small prayer asking for blessing for the audience."</p>

        <p>The following videos are the results generated by the Preaching-AI pipeline.</p>

        <div>
            <div class="col-2 text-center">
                <h3>English</h3>
                <hr>

                <iframe width="100%" height="315" src="https://www.youtube.com/embed/Kr_cMxd1kLs?si=VYQhXsB5ZoEqIhjV" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>

            <div class="col-2 text-center">
                <h3>Chinese</h3>
                <hr>

                <iframe width="100%" height="315" src="https://www.youtube.com/embed/rbPN_7KRjfU?si=ZE5kRnNggbh0xbcU" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
        </div>

        <div>
            <div class="col-2 text-center">
                <h3>French</h3>
                <hr>

                <iframe width="100%" height="315" src="https://www.youtube.com/embed/KiviV3fagpM?si=eQ_5imb-RYiLsm_2" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>

            <div class="col-2 text-center">
                <h3>Hindi</h3>
                <hr>
                
                <iframe width="100%" height="315" src="https://www.youtube.com/embed/XmOm7fHPX_U?si=9hSwqwnhrHlfv685" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
        </div>

        <div>
            <div class="col-2 text-center">
                <h3>Spanish</h3>
                <hr>

                <iframe width="100%" height="315" src="https://www.youtube.com/embed/X7bOlndpSxw?si=RcIdomWo3l6pzvPI" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>

            <div class="col-2 text-center">
                <h3>Portuguese</h3>
                <hr>

                <iframe width="100%" height="315" src="https://www.youtube.com/embed/Th0Um1VKmfQ?si=qh5weHYxRE9CRuis" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            </div>
        </div>
    </section>

    <!-- <section id="paper">
        <h2>Paper</h2>
        <hr>
        <div class="flex-row">
            <div style="box-sizing: border-box; padding: 16px; margin: auto;">
                <a href="https://visgraf.impa.br/papers/i4d-iccv2023-reb.pdf"><img class="screenshot" src="assets/paper-thumbnail.png"></a>
            </div>
            <div style="width: 60%">
                <p><b>Neural Implicit Surface Evolution</b></p>
                <p>Tiago Novello, Vin√≠cius da Silva, Guilherme Schardong, Luiz Schirmer, H√©lio Lopes and Luiz Velho</p>

                <div><span class="material-icons"> description </span><a href="https://visgraf.impa.br/papers/i4d-iccv2023-reb.pdf"> Paper preprint (PDF)</a></div>
                <div><span class="material-icons"> insert_comment </span><a href="assets/novello2023neural.bib"> BibTeX</a></div>
                <div><span class="material-icons"> videocam </span><a href="https://youtu.be/8NqwLkhaRBU"> Video</a></div>

                <p>Please send feedback and questions to <a href="https://sites.google.com/site/tiagonovellodebrito">Tiago Novello</a>.</p>
            </div>
        </div>
    </section>

    <section id="bibtex">
        <h2>Citation</h2>
        <hr>
        <pre style="background-color:#121212;"><code>@inproceedings{novello2022neural,
    title = {Neural Implicit Surface Evolution},
    author = {Novello, Tiago and da Silva, Vin\'icius and Schardong, Guilherme and Schirmer,
        Luiz and Lopes, H\'elio and Velho, Luiz},
    booktitle={Proceedings of the IEEE/CVF international conference on computer vision},
    year = {2023}
} 

</code></pre>
    </section>

    <section id="acknowledgements">
        <h2>Acknowledgements</h2>
        <hr>
        <div class="row">
            <p>
            We would like to thank
            <a href="https://tovacinni.github.io">Towaki Takikawa</a>,
            <a href="https://joeylitalien.github.io">Joey Litalien</a>,
            <a href="https://kangxue.org/">Kangxue Yin</a>,
            <a href="https://scholar.google.de/citations?user=rFd-DiAAAAAJ">Karsten Kreis</a>,
            <a href="https://research.nvidia.com/person/charles-loop">Charles Loop</a>,
            <a href="http://www.cim.mcgill.ca/~derek/">Derek Nowrouzezahrai</a>,
            <a href="https://www.cs.toronto.edu/~jacobson/">Alec Jacobson</a>,
            <a href="https://casual-effects.com/">Morgan McGuire</a> and
            <a href="https://www.cs.toronto.edu/~fidler/">Sanja Fidler</a>
            for licensing the code of the paper <a href="https://nv-tlabs.github.io/nglod/">Neural Geometric Level of Detail:
                Real-time Rendering with Implicit 3D Surfaces</a> and project page under the <a href=https://opensource.org/licenses/MIT>MIT License</a>. This website is based on that page.
            <br/>
            <br/>
            <em>We also thank the <a href="https://graphics.stanford.edu">Stanford Computer Graphics Laboratory</a> for the Bunny, Dragon, Armadillo, and Happy Buddha, acquired through the <a href="http://graphics.stanford.edu/data/3Dscanrep/">Stanford 3D scan repository</a>. Finally, we thank <a href="https://www.cs.cmu.edu/~kmcrane/Projects/ModelRepository/">Keenan Crane</a> for the Spot and Bob models.
            </p>
        </div>
    </section>-->
</div>
</body>

</html>
